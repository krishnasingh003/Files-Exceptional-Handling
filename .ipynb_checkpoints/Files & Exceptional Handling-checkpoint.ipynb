{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9862f7-b239-4153-a069-932999dc4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
    "\n",
    "\n",
    "# Multithreading and multiprocessing are two approaches to parallelism, and they are each suited to different types of tasks. The choice between them depends on the nature of the workload and how the system resources are managed. Here’s an overview of when multithreading or multiprocessing is preferable:\n",
    "\n",
    "# When Multithreading is Preferable\n",
    "# Multithreading involves running multiple threads within a single process, sharing the same memory space. It is typically used when a program needs to perform multiple tasks that are mostly I/O-bound or involve lightweight tasks.\n",
    "\n",
    "# 1. I/O-bound tasks:\n",
    "# Tasks like reading/writing files, making network requests, or querying databases often spend a lot of time waiting for I/O operations to complete. Multithreading is ideal here because while one thread is waiting for I/O, others can continue working, allowing efficient utilization of resources.\n",
    "# Example: A web server handling multiple client requests where each request involves reading/writing to a database or network.\n",
    "\n",
    "# 2. Low-memory overhead:\n",
    "# Since all threads share the same memory space, multithreading incurs less memory overhead than multiprocessing, which creates separate memory spaces for each process.\n",
    "# Example: An application that performs frequent context switching and requires shared access to data structures (like in GUI applications).\n",
    "\n",
    "# 3. Tasks involving shared data:\n",
    "# If tasks need to frequently access or modify shared memory or resources, multithreading can be more efficient because inter-thread communication is easier and faster than inter-process communication (IPC).\n",
    "# Example: A game engine with threads for physics calculations, AI, and graphics rendering, all of which need to update a shared world state.\n",
    "\n",
    "# 4. CPU-bound tasks in languages with lightweight threads:\n",
    "# In some languages or environments (like Java or Go), threads are lightweight, and the Global Interpreter Lock (GIL) is not an issue, making multithreading suitable for CPU-bound tasks.\n",
    "# When Multiprocessing is Preferable\n",
    "# Multiprocessing involves running multiple processes, each with its own memory space, making it more suitable for CPU-bound tasks and environments with heavy parallel processing.\n",
    "\n",
    "# 5. CPU-bound tasks:\n",
    "# When tasks are computationally intensive and consume significant CPU resources (e.g., numerical simulations, video encoding, machine learning model training), multiprocessing is preferable. Each process runs in its own memory space, enabling better CPU utilization, especially on multi-core systems.\n",
    "# Example: Image processing where each process can handle a separate image, or scientific computations using libraries like NumPy and SciPy.\n",
    "\n",
    "# 6. Bypassing the GIL in Python:\n",
    "# In languages like Python, the Global Interpreter Lock (GIL) prevents multiple threads from executing Python bytecode simultaneously. In such cases, multiprocessing is often preferred for CPU-bound tasks to bypass the GIL and fully utilize multiple CPU cores.\n",
    "# Example: A Python application performing intensive data processing or matrix computations.\n",
    "\n",
    "# 7. Fault isolation:\n",
    "# If a task crashes or hangs, it affects only the individual process, not the entire program. This makes multiprocessing a good choice for tasks that might fail or require strict fault isolation.\n",
    "# Example: Running multiple worker processes for data processing, where if one worker crashes, the others continue unaffected.\n",
    "\n",
    "# 8. Scalability and distributed systems:\n",
    "# For systems that need to scale across multiple machines or cores, multiprocessing is more scalable. Processes can be distributed across different machines, and the separation of memory makes it easier to distribute the workload.\n",
    "# Example: Distributed computing frameworks like Apache Spark or MapReduce, which use multiple processes across machines to perform large-scale data processing.\n",
    "\n",
    "# 9. Security and isolation:\n",
    "# If tasks involve sensitive data or must be isolated from each other (e.g., due to security concerns), multiprocessing offers better isolation as processes do not share memory.\n",
    "# Example: Running different microservices or isolated tasks in separate processes to ensure better security and fault tolerance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abf3c1e-6cd9-4cd4-812b-33e5a625d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "# Describe what a process pool is and how it helps in managing multiple processes efficiently\n",
    "\n",
    "\n",
    "# A process pool is a collection of pre-initialized worker processes that can be reused to perform tasks in parallel. It provides an efficient way to manage multiple processes without the overhead of repeatedly creating and destroying processes. Process pools are particularly useful in parallel computing when you have many tasks to execute, and you want to manage them efficiently by distributing the workload across multiple processes.\n",
    "\n",
    "# How Process Pools Work:\n",
    "\n",
    "#  1. Pre-initialization of processes:\n",
    "# Instead of creating a new process for each task, a fixed number of worker processes are created upfront and maintained in a pool. These processes remain alive throughout the execution and are reused for multiple tasks.\n",
    "\n",
    "# 2. Task queueing and scheduling:\n",
    "# When new tasks are submitted to the process pool, they are placed in a queue. The pool manages task assignment by distributing these tasks to available worker processes. Once a process completes a task, it becomes available to pick up another task from the queue.\n",
    "\n",
    "# 3. Efficient resource utilization:\n",
    "\n",
    "# 4. By maintaining a fixed number of processes, process pools limit the number of active processes, preventing system overload. The pool size can be set according to the number of CPU cores or the nature of the workload, ensuring the optimal use of resources without excessive context switching or memory usage.\n",
    "# Automatic load balancing:\n",
    "\n",
    "# 5. The pool efficiently distributes tasks among processes, balancing the workload automatically. Tasks that take longer may be distributed evenly among available workers, while shorter tasks can be handled quickly, keeping all workers engaged.\n",
    "# Termination:\n",
    "\n",
    "# 6. Once all tasks have been completed, the process pool can be closed and the worker processes terminated, freeing up system resources.\n",
    "\n",
    "# Advantages of Using a Process Pool:\n",
    "\n",
    "# 1. Reduced Overhead:\n",
    "# Creating a new process is relatively expensive because it involves setting up its memory space, copying the data, and initializing the necessary resources. A process pool avoids this by reusing processes, reducing the time and computational overhead associated with process creation and destruction.\n",
    "\n",
    "# 2. Better Resource Management:\n",
    "# Process pools allow you to set a limit on the number of worker processes, preventing the system from being overwhelmed by too many simultaneous processes. This is especially important in systems with limited resources, as it ensures that CPU, memory, and I/O bandwidth are used efficiently.\n",
    "\n",
    "# 3. Simplified Parallelism:\n",
    "# Process pools abstract away the complexity of managing individual processes. The user simply submits tasks to the pool, and the pool handles process allocation, task execution, and results collection, making it easier to write parallelized programs.\n",
    "\n",
    "# 4. Load Balancing:\n",
    "# A process pool automatically balances the workload among the available worker processes, distributing tasks efficiently based on their availability and the time they take to complete.\n",
    "\n",
    "# 5. Concurrency Control:\n",
    "# By controlling the size of the pool, you can limit the number of concurrent processes to match the system's capabilities, preventing performance degradation caused by excessive concurrency.\n",
    "\n",
    "# Example Use Cases of Process Pools:\n",
    "\n",
    "# Data processing pipelines:\n",
    "# A process pool can be used to distribute tasks like image processing, data parsing, or computations across multiple cores, ensuring that tasks are processed in parallel without overwhelming system resources.\n",
    "\n",
    "# Web  scraping:\n",
    "# In scenarios where many web pages need to be scraped, a process pool can parallelize the fetching of web pages while ensuring that a controlled number of processes handle the requests simultaneously.\n",
    "\n",
    "# Machine learning model training:\n",
    "# When training multiple models or performing hyperparameter tuning, a process pool can parallelize the training process, making use of multiple CPU cores or distributed systems.\n",
    "\n",
    "# Process Pool in Python (with multiprocessing library):\n",
    "# In Python, the multiprocessing library provides a convenient Pool class to manage process pools. Here's a simple example\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Define a task function to be executed by worker processes\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a process pool with 4 worker processes\n",
    "    with Pool(processes=4) as pool:\n",
    "        # Map the task (squaring numbers) to the worker processes\n",
    "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
    "    \n",
    "    # Print the results\n",
    "    print(results)  # Output: [1, 4, 9, 16, 25]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a59b8f-0e7b-4591-8c7f-7729361244e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a separate process.\n",
      "[1, 4, 9, 16]\n",
      "Hello from worker!\n"
     ]
    }
   ],
   "source": [
    "# Explain what multiprocessing is and why it is used in Python programs.\n",
    "\n",
    "\n",
    "# Multiprocessing is a technique used to run multiple processes simultaneously, with each process having its own memory space and system resources. In Python, multiprocessing allows programs to perform parallel execution, making it possible to utilize multiple CPU cores for executing tasks concurrently. This is particularly important for CPU-bound tasks, which require heavy computational resources and can benefit from true parallelism.\n",
    "\n",
    "# Why Multiprocessing is Used in Python Programs:\n",
    "\n",
    "# 1. Bypassing the Global Interpreter Lock (GIL):\n",
    "# Python’s Global Interpreter Lock (GIL) is a mechanism that allows only one thread to execute Python bytecode at a time. This means that even in multithreaded programs, only one thread can execute Python code on a single CPU core at any given moment, leading to inefficient CPU utilization for CPU-bound tasks.\n",
    "# Multiprocessing avoids the GIL by creating separate processes for each task, each with its own Python interpreter and memory space. This enables true parallelism, allowing multiple CPU cores to execute tasks simultaneously without being constrained by the GIL.\n",
    "\n",
    "# Parallelizing CPU-bound tasks:\n",
    "# 2. Tasks that are computationally intensive (e.g., image processing, scientific simulations, encryption algorithms) benefit from multiprocessing because the workload can be split across multiple processes and run on different CPU cores. This significantly reduces the overall execution time.\n",
    "# Example: When performing a large-scale mathematical computation or machine learning model training, multiprocessing can parallelize the task, utilizing all available CPU cores to run different parts of the computation in parallel.\n",
    "\n",
    "# 3. Independent memory space:\n",
    "# Each process created using multiprocessing has its own independent memory space, which isolates them from one another. This means that each process can execute independently without risking interference or race conditions, which are common in multithreaded programs when multiple threads access shared memory.\n",
    "# Example: In scenarios where processes handle sensitive data or require high levels of isolation (e.g., different stages of a data pipeline), multiprocessing ensures safe execution.\n",
    "\n",
    "# 4. Efficient execution of multiple tasks:\n",
    "# Multiprocessing is ideal for programs that need to perform multiple independent tasks concurrently. Instead of waiting for one task to finish before starting the next, multiple processes can be created, each handling a task in parallel. This speeds up the execution and improves the program’s throughput.\n",
    "# Example: A program that processes multiple files or downloads content from multiple URLs simultaneously can use multiprocessing to handle these tasks in parallel.\n",
    "\n",
    "# 5. Scalability across multiple cores or machines:\n",
    "# Python's multiprocessing can be scaled across multiple cores on a single machine or even across distributed systems. By spawning processes, each running independently, the workload can be distributed efficiently across many processors or machines.\n",
    "# Example: Distributed computing frameworks, such as those used in big data processing (e.g., Apache Spark or Dask), leverage multiprocessing to distribute tasks across a cluster of machines.\n",
    "\n",
    "# How Multiprocessing Works in Python:\n",
    "# Python’s multiprocessing library provides a set of tools to create and manage processes. Each process runs independently, and data is communicated between them via pipes, queues, or shared memory.\n",
    "\n",
    "# Here’s a breakdown of how multiprocessing is used:\n",
    "\n",
    "# Creating processes:\n",
    "# The Process class is used to create new processes. Each process runs its own instance of the Python interpreter.\n",
    "from multiprocessing import Process\n",
    "\n",
    "def task():\n",
    "    print(\"This is a separate process.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = Process(target=task)\n",
    "    p.start()  # Start the process\n",
    "    p.join()   # Wait for the process to finish\n",
    "\n",
    "    \n",
    "\n",
    "# Process pools:\n",
    "# For managing multiple processes efficiently, the Pool class provides an easy way to run tasks in parallel across a fixed number of processes.\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(4) as pool:  # Create a pool of 4 worker processes\n",
    "        results = pool.map(square, [1, 2, 3, 4])\n",
    "    print(results)  # Output: [1, 4, 9, 16]\n",
    "\n",
    "# Inter-process communication (IPC):\n",
    "# Processes in Python do not share memory by default, but communication between processes can be achieved using pipes or queues    \n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def worker(queue):\n",
    "    queue.put(\"Hello from worker!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queue = Queue()\n",
    "    p = Process(target=worker, args=(queue,))\n",
    "    p.start()\n",
    "    print(queue.get())  # Output: Hello from worker!\n",
    "    p.join()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf35e7d-6ddf-4ff4-9407-cef3431ffb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 to the list.\n",
      "Added 1 to the list.\n",
      "Removed 0 from the list.\n",
      "Added 2 to the list.\n",
      "Removed 1 from the list.\n",
      "Added 3 to the list.\n",
      "Added 4 to the list.\n",
      "Removed 2 from the list.\n",
      "Added 5 to the list.\n",
      "Added 6 to the list.\n",
      "Removed 3 from the list.\n",
      "Added 7 to the list.\n",
      "Added 8 to the list.\n",
      "Removed 4 from the list.\n",
      "Added 9 to the list.\n",
      "Removed 5 from the list.\n",
      "Removed 6 from the list.\n",
      "Removed 7 from the list.\n",
      "Removed 8 from the list.\n",
      "Removed 9 from the list.\n",
      "Final list: []\n"
     ]
    }
   ],
   "source": [
    "# Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock\n",
    "\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared list and a lock\n",
    "shared_list = []\n",
    "list_lock = threading.Lock()\n",
    "\n",
    "# Function for adding numbers to the list\n",
    "def add_to_list():\n",
    "    for i in range(10):\n",
    "        time.sleep(1)  # Simulate a delay for adding\n",
    "        with list_lock:  # Acquire the lock before modifying the list\n",
    "            shared_list.append(i)\n",
    "            print(f\"Added {i} to the list.\")\n",
    "            \n",
    "# Function for removing numbers from the list\n",
    "def remove_from_list():\n",
    "    for i in range(10):\n",
    "        time.sleep(2)  # Simulate a delay for removing\n",
    "        with list_lock:  # Acquire the lock before modifying the list\n",
    "            if shared_list:\n",
    "                removed = shared_list.pop(0)\n",
    "                print(f\"Removed {removed} from the list.\")\n",
    "            else:\n",
    "                print(\"List is empty, cannot remove.\")\n",
    "\n",
    "# Create threads for adding and removing\n",
    "adder_thread = threading.Thread(target=add_to_list)\n",
    "remover_thread = threading.Thread(target=remove_from_list)\n",
    "\n",
    "# Start the threads\n",
    "adder_thread.start()\n",
    "remover_thread.start()\n",
    "\n",
    "# Wait for both threads to complete\n",
    "adder_thread.join()\n",
    "remover_thread.join()\n",
    "\n",
    "print(\"Final list:\", shared_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cff19c65-9f78-4a7b-b851-a2f43e3ba578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from process\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
    "\n",
    "\n",
    "# In Python, when dealing with concurrency (threads) and parallelism (processes), it is important to ensure safe communication and data sharing between threads or processes. Python provides several methods and tools for safely sharing data while avoiding issues like race conditions, deadlocks, or corrupted data. These methods vary depending on whether you're using threads or processes, as the memory model for each is different.\n",
    "\n",
    "# Safely Sharing Data Between Threads\n",
    "# Since threads share the same memory space, synchronization mechanisms are necessary to ensure that threads do not simultaneously access or modify shared data in ways that cause race conditions. Python’s threading module provides several tools for safely sharing data between threads:\n",
    "\n",
    "# 1. Locks (threading.Lock)\n",
    "# A Lock is the simplest synchronization primitive. It ensures that only one thread can access shared data at a time by acquiring and releasing the lock.\n",
    "# When a thread acquires the lock, other threads must wait until it is released before accessing the shared resource\n",
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def update_shared_resource():\n",
    "    with lock:\n",
    "        # Safely access or modify shared data\n",
    "        pass\n",
    "# Use case: Prevents race conditions when threads modify shared resources like lists, dictionaries, or files.\n",
    "\n",
    "\n",
    "# 2. RLocks (threading.RLock)\n",
    "# A Reentrant Lock (RLock) allows a thread to acquire the lock multiple times. This is useful when the same thread needs to acquire a lock while already holding it (e.g., recursive function calls).\n",
    "lock = threading.RLock()\n",
    "# Use case: Suitable for more complex programs where a thread might need to acquire a lock it already hold\n",
    "\n",
    "# 3. Condition Variables (threading.Condition)\n",
    "# A Condition allows one or more threads to wait until they are notified by another thread. Condition variables are used with a lock, allowing threads to wait for some condition to be met before proceeding\n",
    "#condition = threading.Condition()\n",
    "\n",
    "def wait_for_condition():\n",
    "    with condition:\n",
    "        condition.wait()  # Wait for the condition to be notified\n",
    "        # Perform actions after notification\n",
    "# Use case: Useful for coordinating the execution order between threads (e.g., a producer-consumer problem where the producer notifies the consumer that data is available)\n",
    "\n",
    "\n",
    "# 4. Semaphores (threading.Semaphore)\n",
    "# A Semaphore controls access to a resource by limiting the number of threads that can access it concurrently. It maintains a counter, and threads can increment or decrement it as they acquire or release access to a shared resource\n",
    "semaphore = threading.Semaphore(2)  # Allow up to 2 threads to access the resource\n",
    "# Use case: Useful when multiple threads can access a shared resource, but there should be a limit on how many can access it concurrently (e.g., database connections).\n",
    "\n",
    "\n",
    "# 5. Event (threading.Event)\n",
    "# An Event is a flag that can be set or cleared. Threads can wait for an event to be set (activated) before continuing execution.\n",
    "event = threading.Event()\n",
    "\n",
    "def wait_for_event():\n",
    "    event.wait()  # Wait until the event is set\n",
    "# Use case: Used to signal one or more threads to start or stop processing based on some external condition.\n",
    "\n",
    "# 6. Queues (queue.Queue)\n",
    "# A Queue is a thread-safe data structure used for communication between threads. Threads can safely add or remove items from the queue without requiring manual locks, as queue.Queue handles all synchronization internally.\n",
    "import queue\n",
    "q = queue.Queue()\n",
    "\n",
    "q.put(10)  # Add item to the queue\n",
    "item = q.get()  # Remove item from the queue\n",
    "# Use case: Suitable for the producer-consumer pattern where threads produce and consume items from a shared queue\n",
    "\n",
    "\n",
    "# Safely Sharing Data Between Processes\n",
    "# Processes do not share memory space like threads, so special mechanisms are required for inter-process communication (IPC). Python’s multiprocessing module provides several tools for safely sharing data between processes.\n",
    "\n",
    "# 1. Queues (multiprocessing.Queue)\n",
    "# Similar to queue.Queue, multiprocessing.Queue allows safe communication between processes. Items can be passed between processes via the queue, and it handles the necessary synchronization internally.\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def worker(q):\n",
    "    q.put('Data from process')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    p = Process(target=worker, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())  # Retrieve data from the queue\n",
    "    p.join()\n",
    "# Use case: Passing data between producer and consumer processes.\n",
    "\n",
    "# 2. Pipes (multiprocessing.Pipe)\n",
    "# A Pipe is a two-way communication channel between two processes. Data can be sent from one end of the pipe and received from the other.\n",
    "from multiprocessing import Pipe\n",
    "\n",
    "parent_conn, child_conn = Pipe()\n",
    "\n",
    "def worker(conn):\n",
    "    conn.send('Data from process')\n",
    "# Use case: Useful for two-process communication.\n",
    "\n",
    "# 3. Shared Memory (multiprocessing.Value and Array)\n",
    "# Shared memory allows multiple processes to share variables or arrays. multiprocessing.Value and multiprocessing.Array provide shared, memory-backed data types for safe inter-process communication.\n",
    "from multiprocessing import Value, Process\n",
    "\n",
    "shared_value = Value('i', 0)  # Shared integer\n",
    "\n",
    "def increment_value(shared_value):\n",
    "    with shared_value.get_lock():  # Ensure atomic operations\n",
    "        shared_value.value += 1\n",
    "# Use case: Used when processes need to share data directly rather than passing it through queues or pipes.\n",
    "\n",
    "# 4. Managers (multiprocessing.Manager)\n",
    "# Managers provide a high-level interface to share data between processes. Using a manager, you can share complex data types like lists, dictionaries, or other objects between processes.\n",
    "from multiprocessing import Manager\n",
    "\n",
    "def worker(shared_list):\n",
    "    shared_list.append(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    manager = Manager()\n",
    "    shared_list = manager.list()\n",
    "\n",
    "    p = Process(target=worker, args=(shared_list,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(shared_list)  # Output: [1]\n",
    "\n",
    "# 5. Locks (multiprocessing.Lock)\n",
    "# Just like in threading, a Lock can be used in multiprocessing to prevent multiple processes from modifying shared data at the same time.\n",
    "from multiprocessing import Lock\n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "def critical_section():\n",
    "    with lock:\n",
    "        # Safely modify shared resource\n",
    "        pass\n",
    "# Use case: Prevent race conditions when multiple processes access shared resources.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32102098-5749-47af-9dfa-7bc4769385d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception caught in thread: An error occurred in the thread.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ThreadPoolExecutor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative value error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m x\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mThreadPoolExecutor\u001b[49m(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     54\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(worker, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ThreadPoolExecutor' is not defined"
     ]
    }
   ],
   "source": [
    "# Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
    "\n",
    "\n",
    "\n",
    "# Handling exceptions in concurrent programs is crucial for several reasons. In concurrent systems, where multiple threads or processes execute independently and in parallel, the failure of one thread or process can lead to unexpected outcomes, corrupted data, deadlocks, or crashes that affect the entire program. By properly handling exceptions, you ensure that your program can gracefully recover from errors, maintain stability, and provide meaningful feedback.\n",
    "\n",
    "# Why Exception Handling is Crucial in Concurrent Programs:\n",
    "\n",
    "# Preventing Program Crashes:\n",
    "# Without proper exception handling, an uncaught exception in one thread or process can crash the entire program. Since threads and processes often interact with shared resources, the failure of one can lead to widespread issues in the system.\n",
    "\n",
    "# Ensuring Data Integrity:\n",
    "# In concurrent programs, multiple threads or processes may access shared resources such as memory, files, or databases. If an exception occurs and is not handled properly, it may leave these shared resources in an inconsistent or corrupted state. For example, a thread might start writing to a file and crash halfway through, leaving the file in an incomplete state.\n",
    "\n",
    "# Avoiding Deadlocks and Resource Leaks:\n",
    "# If exceptions are not handled properly, locks, semaphores, or other synchronization primitives may not be released, leading to deadlocks. Similarly, resources like file handles, network connections, or memory might not be properly freed, causing resource leaks.\n",
    "\n",
    "# Detecting Failures in Worker Threads/Processes:\n",
    "# In concurrent programs, especially in thread pools or process pools, it is important to detect failures in worker threads or processes. If a worker crashes silently, the main program may continue running as if the task was successfully completed, leading to incorrect results or incomplete work.\n",
    "\n",
    "# Graceful Shutdown:\n",
    "# When exceptions occur, it is essential to perform any necessary cleanup, such as releasing locks, closing files, or notifying other threads or processes. This ensures that the program can shut down gracefully and avoid leaving resources in an unusable state.\n",
    "\n",
    "# Debugging and Maintenance:\n",
    "# Unhandled exceptions in concurrent programs can be difficult to trace because threads and processes execute independently. Exception handling allows you to capture error messages and stack traces, making it easier to identify the source of a failure in a concurrent environment.\n",
    "\n",
    "# Techniques for Handling Exceptions in Concurrent Programs\n",
    "# 1. Try-Except Blocks\n",
    "# The most basic technique is using try-except blocks to catch and handle exceptions within individual threads or processes. This ensures that if an error occurs within a thread or process, it is properly handled, and the program can continue execution\n",
    "import threading\n",
    "\n",
    "def worker():\n",
    "    try:\n",
    "        # Some operation that may raise an exception\n",
    "        raise ValueError(\"An error occurred in the thread.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception caught in thread: {e}\")\n",
    "\n",
    "thread = threading.Thread(target=worker)\n",
    "thread.start()\n",
    "# Use case: Basic error handling for isolated exceptions within individual threads or processes.\n",
    "\n",
    "# 2. Exception Handling in Thread and Process Pools\n",
    "# When using thread or process pools (e.g., ThreadPoolExecutor, multiprocessing.Pool), exceptions may occur in worker threads or processes. These exceptions need to be captured and handled appropriately.\n",
    "\n",
    "# In ThreadPoolExecutor or ProcessPoolExecutor, exceptions are raised when retrieving results using future.result()from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def worker(x):\n",
    "    if x < 0:\n",
    "        raise ValueError(\"Negative value error\")\n",
    "    return x * x\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = [executor.submit(worker, i) for i in [1, -2, 3]]\n",
    "    for future in futures:\n",
    "        try:\n",
    "            result = future.result()  # Retrieve result or exception\n",
    "            print(f\"Result: {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in worker: {e}\")\n",
    "# Use case: Handling exceptions raised in worker threads or processes and ensuring they are caught when retrieving results.\n",
    "\n",
    "# 3. Exception Propagation in Multiprocessing\n",
    "# In the multiprocessing module, exceptions that occur in a child process are not automatically propagated to the parent process. You can catch exceptions inside the worker process and propagate them using queues or pipes.\n",
    "# Example with a queue for propagating exceptions:\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def worker(q):\n",
    "    try:\n",
    "        raise ValueError(\"An error occurred in the process.\")\n",
    "    except Exception as e:\n",
    "        q.put(e)  # Put exception in queue\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    p = Process(target=worker, args=(q,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    # Retrieve the exception from the queue\n",
    "    if not q.empty():\n",
    "        exception = q.get()\n",
    "        print(f\"Exception caught from process: {exception}\")\n",
    "# Use case: Safely capturing exceptions in child processes and passing them to the main process for handling.\n",
    "\n",
    "# 4. Using Thread.join() with Timeout\n",
    "# When dealing with long-running threads, it's often helpful to use thread.join(timeout) to ensure that threads are not blocking indefinitely. If the thread fails to complete within the expected time, you can handle this scenario and possibly retry the operation or log the issue.\n",
    "thread = threading.Thread(target=worker)\n",
    "thread.start()\n",
    "thread.join(timeout=5)  # Wait for 5 seconds\n",
    "\n",
    "if thread.is_alive():\n",
    "    print(\"Thread is still running, taking action.\")\n",
    "# Use case: Avoid situations where a thread might be stuck in an infinite loop or deadlock, and handle the timeout gracefully.\n",
    "\n",
    "# 5. Thread/Process-Safe Queues for Error Reporting\n",
    "# In complex systems where multiple threads or processes are performing various tasks, a thread-safe or process-safe queue can be used to collect errors and handle them centrally.\n",
    "from queue import Queue\n",
    "import threading\n",
    "\n",
    "error_queue = Queue()\n",
    "\n",
    "def worker():\n",
    "    try:\n",
    "        # Perform task\n",
    "        raise ValueError(\"An error occurred\")\n",
    "    except Exception as e:\n",
    "        error_queue.put(e)\n",
    "\n",
    "threads = [threading.Thread(target=worker) for _ in range(5)]\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "# Handle all errors\n",
    "while not error_queue.empty():\n",
    "    error = error_queue.get()\n",
    "    print(f\"Error caught: {error}\")\n",
    "# Use case: Centralized error handling in concurrent environments, particularly in worker pools or systems with many threads or processes.\n",
    "\n",
    "# 6. Graceful Shutdown Using Signals (for Multiprocessing)\n",
    "# For processes, particularly long-running ones, handling signals (e.g., SIGINT, SIGTERM) allows you to gracefully shut down processes in response to exceptions or external events.\n",
    "import multiprocessing\n",
    "import signal\n",
    "import time\n",
    "\n",
    "def handle_signal(signum, frame):\n",
    "    print(f\"Received signal {signum}, shutting down gracefully.\")\n",
    "    exit(1)\n",
    "\n",
    "def worker():\n",
    "    signal.signal(signal.SIGINT, handle_signal)\n",
    "    while True:\n",
    "        time.sleep(1)  # Simulate work\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = multiprocessing.Process(target=worker)\n",
    "    p.start()\n",
    "    p.join()\n",
    "# Use case: Graceful handling of shutdown signals in multiprocess applications (e.g., in web servers or distributed systems).\n",
    "\n",
    "# 7. Logging Exceptions\n",
    "# A good practice in concurrent programs is to use logging to capture and track exceptions. This helps in debugging by providing a detailed log of when and where the exception occurred.\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "def worker():\n",
    "    try:\n",
    "        raise ValueError(\"An error occurred\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception in worker: {e}\")\n",
    "\n",
    "# Use case: Maintaining logs for debugging and operational monitoring in production systems.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d6bb9e3-fbe7-485f-bef7-af9804e32c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 7 is 5040\n",
      "Factorial of 8 is 40320\n",
      "Factorial of 9 is 362880\n",
      "Factorial of 10 is 3628800\n",
      "Factorial of 6 is 720\n",
      "Factorial of 3 is 6\n",
      "Factorial of 2 is 2\n",
      "Factorial of 4 is 24\n",
      "Factorial of 1 is 1\n",
      "Factorial of 5 is 120\n"
     ]
    }
   ],
   "source": [
    "# Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "\n",
    "\n",
    "# Here's a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently. The program defines a function to compute the factorial of a given number and then uses a thread pool to execute this function for the specified range of numbers.\n",
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "def calculate_factorial(n):\n",
    "    \"\"\"Calculate the factorial of a number.\"\"\"\n",
    "    return math.factorial(n)\n",
    "\n",
    "def main():\n",
    "    # List of numbers from 1 to 10\n",
    "    numbers = list(range(1, 11))\n",
    "\n",
    "    # Using ThreadPoolExecutor to manage threads\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit the factorial calculation tasks to the executor\n",
    "        futures = {executor.submit(calculate_factorial, num): num for num in numbers}\n",
    "        \n",
    "        # Retrieve the results as they complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            number = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(f\"Factorial of {number} is {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating factorial of {number}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19080bd8-0125-4f33-9214-d137287f5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square of 1 is 1\n",
      "Square of 2 is 4\n",
      "Square of 3 is 9\n",
      "Square of 4 is 16\n",
      "Square of 5 is 25\n",
      "Square of 6 is 36\n",
      "Square of 7 is 49\n",
      "Square of 8 is 64\n",
      "Square of 9 is 81\n",
      "Square of 10 is 100\n",
      "Time taken with 2 processes: 0.0019 seconds\n",
      "----------------------------------------\n",
      "Square of 1 is 1\n",
      "Square of 2 is 4\n",
      "Square of 3 is 9\n",
      "Square of 4 is 16\n",
      "Square of 5 is 25\n",
      "Square of 6 is 36\n",
      "Square of 7 is 49\n",
      "Square of 8 is 64\n",
      "Square of 9 is 81\n",
      "Square of 10 is 100\n",
      "Time taken with 4 processes: 0.0015 seconds\n",
      "----------------------------------------\n",
      "Square of 1 is 1\n",
      "Square of 2 is 4\n",
      "Square of 3 is 9\n",
      "Square of 4 is 16\n",
      "Square of 5 is 25\n",
      "Square of 6 is 36\n",
      "Square of 7 is 49\n",
      "Square of 8 is 64\n",
      "Square of 9 is 81\n",
      "Square of 10 is 100\n",
      "Time taken with 8 processes: 0.0014 seconds\n",
      "----------------------------------------\n",
      "Pool size: 2, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0247 seconds\n",
      "Pool size: 4, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0418 seconds\n",
      "Pool size: 8, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0735 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).\n",
    "\n",
    "\n",
    "# Here's a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program measures the time taken to perform this computation with different pool sizes (2, 4, and 8 processes).\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def square_number(n):\n",
    "    \"\"\"Compute the square of a number.\"\"\"\n",
    "    return n * n\n",
    "\n",
    "def compute_squares(pool_size):\n",
    "    \"\"\"Compute squares of numbers from 1 to 10 using a pool of workers.\"\"\"\n",
    "    numbers = list(range(1, 11))\n",
    "\n",
    "    # Create a pool of workers with the specified size\n",
    "    with multiprocessing.Pool(processes=pool_size) as pool:\n",
    "        # Measure the start time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Compute the squares in parallel\n",
    "        results = pool.map(square_number, numbers)\n",
    "        \n",
    "        # Measure the end time\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Print results\n",
    "        for number, result in zip(numbers, results):\n",
    "            print(f\"Square of {number} is {result}\")\n",
    "        \n",
    "        # Print the time taken\n",
    "        print(f\"Time taken with {pool_size} processes: {end_time - start_time:.4f} seconds\")\n",
    "        print('-' * 40)\n",
    "\n",
    "def main():\n",
    "    # List of pool sizes to test\n",
    "    pool_sizes = [2, 4, 8]\n",
    "    \n",
    "    # Run the computation for each pool size\n",
    "    for size in pool_sizes:\n",
    "        compute_squares(size)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    \n",
    "    \n",
    "# Here’s a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program measures the time taken to perform this computation using different pool sizes (2, 4, and 8 processes).\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def compute_square(n):\n",
    "    \"\"\"Compute the square of a number.\"\"\"\n",
    "    return n * n\n",
    "\n",
    "def main():\n",
    "    # List of numbers from 1 to 10\n",
    "    numbers = list(range(1, 11))\n",
    "    \n",
    "    # Different pool sizes to test\n",
    "    pool_sizes = [2, 4, 8]\n",
    "\n",
    "    for size in pool_sizes:\n",
    "        # Start measuring time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Create a pool of processes\n",
    "        with multiprocessing.Pool(processes=size) as pool:\n",
    "            # Map the compute_square function to the numbers\n",
    "            results = pool.map(compute_square, numbers)\n",
    "\n",
    "        # End measuring time\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Print results and time taken\n",
    "        print(f\"Pool size: {size}, Results: {results}, Time taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d0a34-a90b-4727-a322-26f9ea2a066c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
